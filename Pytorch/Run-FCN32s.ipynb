{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Tesla V100-SXM2-16GB\n",
      "Memory Usage:\n",
      "Allocated: 4.5 GB\n",
      "Cached:    14.8 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.1.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.18.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.2.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.15.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.29.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (3.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.34.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.14.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow==1.15.0) (3.2.1)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (46.1.3.post20200330)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/FCN32s'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9ab855b5f76237b0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9ab855b5f76237b0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ckpt/mapillary-fcn32s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100)), ReLU(inplace=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 20 / 1125], [train loss 546858.31250]\n",
      "[epoch 1], [iter 40 / 1125], [train loss 541954.12500]\n",
      "[epoch 1], [iter 60 / 1125], [train loss 535820.75000]\n",
      "[epoch 1], [iter 80 / 1125], [train loss 528367.43750]\n",
      "[epoch 1], [iter 100 / 1125], [train loss 520565.15625]\n",
      "[epoch 1], [iter 120 / 1125], [train loss 511687.43750]\n",
      "[epoch 1], [iter 140 / 1125], [train loss 501614.53125]\n",
      "[epoch 1], [iter 160 / 1125], [train loss 489945.75000]\n",
      "[epoch 1], [iter 180 / 1125], [train loss 477629.43750]\n",
      "[epoch 1], [iter 200 / 1125], [train loss 464735.50000]\n",
      "[epoch 1], [iter 220 / 1125], [train loss 452012.46875]\n",
      "[epoch 1], [iter 240 / 1125], [train loss 440243.25000]\n",
      "[epoch 1], [iter 260 / 1125], [train loss 429234.71875]\n",
      "[epoch 1], [iter 280 / 1125], [train loss 419357.00000]\n",
      "[epoch 1], [iter 300 / 1125], [train loss 409985.87500]\n",
      "[epoch 1], [iter 320 / 1125], [train loss 401326.46875]\n",
      "[epoch 1], [iter 340 / 1125], [train loss 393110.09375]\n",
      "[epoch 1], [iter 360 / 1125], [train loss 385742.50000]\n",
      "[epoch 1], [iter 380 / 1125], [train loss 378642.21875]\n",
      "[epoch 1], [iter 400 / 1125], [train loss 371926.40625]\n",
      "[epoch 1], [iter 420 / 1125], [train loss 365936.65625]\n",
      "[epoch 1], [iter 440 / 1125], [train loss 360154.34375]\n",
      "[epoch 1], [iter 460 / 1125], [train loss 354777.75000]\n",
      "[epoch 1], [iter 480 / 1125], [train loss 349423.21875]\n",
      "[epoch 1], [iter 500 / 1125], [train loss 343997.28125]\n",
      "[epoch 1], [iter 520 / 1125], [train loss 339414.90625]\n",
      "[epoch 1], [iter 540 / 1125], [train loss 335070.37500]\n",
      "[epoch 1], [iter 560 / 1125], [train loss 330664.12500]\n",
      "[epoch 1], [iter 580 / 1125], [train loss 326566.28125]\n",
      "[epoch 1], [iter 600 / 1125], [train loss 322776.56250]\n",
      "[epoch 1], [iter 620 / 1125], [train loss 319112.87500]\n",
      "[epoch 1], [iter 640 / 1125], [train loss 315448.28125]\n",
      "[epoch 1], [iter 660 / 1125], [train loss 312023.46875]\n",
      "[epoch 1], [iter 680 / 1125], [train loss 308603.75000]\n",
      "[epoch 1], [iter 700 / 1125], [train loss 305365.71875]\n",
      "[epoch 1], [iter 720 / 1125], [train loss 302223.15625]\n",
      "[epoch 1], [iter 740 / 1125], [train loss 299372.31250]\n",
      "[epoch 1], [iter 760 / 1125], [train loss 296470.90625]\n",
      "[epoch 1], [iter 780 / 1125], [train loss 293784.90625]\n",
      "[epoch 1], [iter 800 / 1125], [train loss 291263.12500]\n",
      "[epoch 1], [iter 820 / 1125], [train loss 288743.21875]\n",
      "[epoch 1], [iter 840 / 1125], [train loss 286520.43750]\n",
      "[epoch 1], [iter 860 / 1125], [train loss 284175.62500]\n",
      "[epoch 1], [iter 880 / 1125], [train loss 281868.75000]\n",
      "[epoch 1], [iter 900 / 1125], [train loss 279707.71875]\n",
      "[epoch 1], [iter 920 / 1125], [train loss 277494.09375]\n",
      "[epoch 1], [iter 940 / 1125], [train loss 275513.62500]\n",
      "[epoch 1], [iter 960 / 1125], [train loss 273575.81250]\n",
      "[epoch 1], [iter 980 / 1125], [train loss 271691.18750]\n",
      "[epoch 1], [iter 1000 / 1125], [train loss 270004.28125]\n",
      "[epoch 1], [iter 1020 / 1125], [train loss 268149.62500]\n",
      "[epoch 1], [iter 1040 / 1125], [train loss 266559.18750]\n",
      "[epoch 1], [iter 1060 / 1125], [train loss 264938.84375]\n",
      "[epoch 1], [iter 1080 / 1125], [train loss 263306.12500]\n",
      "[epoch 1], [iter 1100 / 1125], [train loss 261731.40625]\n",
      "[epoch 1], [iter 1120 / 1125], [train loss 260257.89062]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 1], [val loss 660996.93750], [acc 0.28886], [acc_cls 0.05216], [mean_iu 0.02006], [fwavacc 0.09840]\n",
      "best record: [val loss 660996.93750], [acc 0.28886], [acc_cls 0.05216], [mean_iu 0.02006], [fwavacc 0.09840], [epoch 1]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 2], [iter 20 / 1125], [train loss 177298.34375]\n",
      "[epoch 2], [iter 40 / 1125], [train loss 173764.84375]\n",
      "[epoch 2], [iter 60 / 1125], [train loss 171860.76562]\n",
      "[epoch 2], [iter 80 / 1125], [train loss 172364.31250]\n",
      "[epoch 2], [iter 100 / 1125], [train loss 172447.15625]\n",
      "[epoch 2], [iter 120 / 1125], [train loss 171214.32812]\n",
      "[epoch 2], [iter 140 / 1125], [train loss 171018.92188]\n",
      "[epoch 2], [iter 160 / 1125], [train loss 171217.48438]\n",
      "[epoch 2], [iter 180 / 1125], [train loss 170720.43750]\n",
      "[epoch 2], [iter 200 / 1125], [train loss 170609.31250]\n",
      "[epoch 2], [iter 220 / 1125], [train loss 170609.82812]\n",
      "[epoch 2], [iter 240 / 1125], [train loss 170484.64062]\n",
      "[epoch 2], [iter 260 / 1125], [train loss 170527.10938]\n",
      "[epoch 2], [iter 280 / 1125], [train loss 170124.50000]\n",
      "[epoch 2], [iter 300 / 1125], [train loss 169816.07812]\n",
      "[epoch 2], [iter 320 / 1125], [train loss 169490.06250]\n",
      "[epoch 2], [iter 340 / 1125], [train loss 169005.65625]\n",
      "[epoch 2], [iter 360 / 1125], [train loss 168882.31250]\n",
      "[epoch 2], [iter 380 / 1125], [train loss 168377.90625]\n",
      "[epoch 2], [iter 400 / 1125], [train loss 168303.96875]\n",
      "[epoch 2], [iter 420 / 1125], [train loss 167869.98438]\n",
      "[epoch 2], [iter 440 / 1125], [train loss 167486.10938]\n",
      "[epoch 2], [iter 460 / 1125], [train loss 167264.46875]\n",
      "[epoch 2], [iter 480 / 1125], [train loss 167169.42188]\n",
      "[epoch 2], [iter 500 / 1125], [train loss 167329.10938]\n",
      "[epoch 2], [iter 520 / 1125], [train loss 166942.03125]\n",
      "[epoch 2], [iter 540 / 1125], [train loss 166952.60938]\n",
      "[epoch 2], [iter 560 / 1125], [train loss 166646.51562]\n",
      "[epoch 2], [iter 580 / 1125], [train loss 166288.32812]\n",
      "[epoch 2], [iter 600 / 1125], [train loss 166265.96875]\n",
      "[epoch 2], [iter 620 / 1125], [train loss 166098.15625]\n",
      "[epoch 2], [iter 640 / 1125], [train loss 165933.73438]\n",
      "[epoch 2], [iter 660 / 1125], [train loss 165684.43750]\n",
      "[epoch 2], [iter 680 / 1125], [train loss 165398.43750]\n",
      "[epoch 2], [iter 700 / 1125], [train loss 165177.20312]\n",
      "[epoch 2], [iter 720 / 1125], [train loss 164873.81250]\n",
      "[epoch 2], [iter 740 / 1125], [train loss 164737.67188]\n",
      "[epoch 2], [iter 760 / 1125], [train loss 164443.93750]\n",
      "[epoch 2], [iter 780 / 1125], [train loss 164135.34375]\n",
      "[epoch 2], [iter 800 / 1125], [train loss 163961.45312]\n",
      "[epoch 2], [iter 820 / 1125], [train loss 163768.54688]\n",
      "[epoch 2], [iter 840 / 1125], [train loss 163559.45312]\n",
      "[epoch 2], [iter 860 / 1125], [train loss 163346.03125]\n",
      "[epoch 2], [iter 880 / 1125], [train loss 163237.29688]\n",
      "[epoch 2], [iter 900 / 1125], [train loss 163008.62500]\n",
      "[epoch 2], [iter 920 / 1125], [train loss 162748.31250]\n",
      "[epoch 2], [iter 940 / 1125], [train loss 162466.53125]\n",
      "[epoch 2], [iter 960 / 1125], [train loss 162178.18750]\n",
      "[epoch 2], [iter 980 / 1125], [train loss 161894.64062]\n",
      "[epoch 2], [iter 1000 / 1125], [train loss 161773.00000]\n",
      "[epoch 2], [iter 1020 / 1125], [train loss 161609.62500]\n",
      "[epoch 2], [iter 1040 / 1125], [train loss 161499.78125]\n",
      "[epoch 2], [iter 1060 / 1125], [train loss 161276.96875]\n",
      "[epoch 2], [iter 1080 / 1125], [train loss 161086.23438]\n",
      "[epoch 2], [iter 1100 / 1125], [train loss 160774.04688]\n",
      "[epoch 2], [iter 1120 / 1125], [train loss 160650.48438]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 2], [val loss 757817.18750], [acc 0.30116], [acc_cls 0.06855], [mean_iu 0.02927], [fwavacc 0.10837]\n",
      "best record: [val loss 757817.18750], [acc 0.30116], [acc_cls 0.06855], [mean_iu 0.02927], [fwavacc 0.10837], [epoch 2]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 3], [iter 20 / 1125], [train loss 153160.03125]\n",
      "[epoch 3], [iter 40 / 1125], [train loss 150211.75000]\n",
      "[epoch 3], [iter 60 / 1125], [train loss 149763.57812]\n",
      "[epoch 3], [iter 80 / 1125], [train loss 150034.67188]\n",
      "[epoch 3], [iter 100 / 1125], [train loss 149836.23438]\n",
      "[epoch 3], [iter 120 / 1125], [train loss 149585.82812]\n",
      "[epoch 3], [iter 140 / 1125], [train loss 149510.03125]\n",
      "[epoch 3], [iter 160 / 1125], [train loss 149788.32812]\n",
      "[epoch 3], [iter 180 / 1125], [train loss 149620.20312]\n",
      "[epoch 3], [iter 200 / 1125], [train loss 149304.31250]\n",
      "[epoch 3], [iter 220 / 1125], [train loss 149487.31250]\n",
      "[epoch 3], [iter 240 / 1125], [train loss 149131.90625]\n",
      "[epoch 3], [iter 260 / 1125], [train loss 149337.50000]\n",
      "[epoch 3], [iter 280 / 1125], [train loss 149426.00000]\n",
      "[epoch 3], [iter 300 / 1125], [train loss 149367.92188]\n",
      "[epoch 3], [iter 320 / 1125], [train loss 149204.95312]\n",
      "[epoch 3], [iter 340 / 1125], [train loss 149065.03125]\n",
      "[epoch 3], [iter 360 / 1125], [train loss 149157.56250]\n",
      "[epoch 3], [iter 380 / 1125], [train loss 149266.92188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3], [iter 400 / 1125], [train loss 148996.35938]\n",
      "[epoch 3], [iter 420 / 1125], [train loss 148840.50000]\n",
      "[epoch 3], [iter 440 / 1125], [train loss 148698.43750]\n",
      "[epoch 3], [iter 460 / 1125], [train loss 148384.82812]\n",
      "[epoch 3], [iter 480 / 1125], [train loss 148193.50000]\n",
      "[epoch 3], [iter 500 / 1125], [train loss 148036.85938]\n",
      "[epoch 3], [iter 520 / 1125], [train loss 148057.26562]\n",
      "[epoch 3], [iter 540 / 1125], [train loss 148083.21875]\n",
      "[epoch 3], [iter 560 / 1125], [train loss 147740.31250]\n",
      "[epoch 3], [iter 580 / 1125], [train loss 147541.29688]\n",
      "[epoch 3], [iter 600 / 1125], [train loss 147335.85938]\n",
      "[epoch 3], [iter 620 / 1125], [train loss 147355.96875]\n",
      "[epoch 3], [iter 640 / 1125], [train loss 147363.06250]\n",
      "[epoch 3], [iter 660 / 1125], [train loss 147410.54688]\n",
      "[epoch 3], [iter 680 / 1125], [train loss 147121.85938]\n",
      "[epoch 3], [iter 700 / 1125], [train loss 147140.56250]\n",
      "[epoch 3], [iter 720 / 1125], [train loss 147083.62500]\n",
      "[epoch 3], [iter 740 / 1125], [train loss 146982.14062]\n",
      "[epoch 3], [iter 760 / 1125], [train loss 146879.51562]\n",
      "[epoch 3], [iter 780 / 1125], [train loss 146816.98438]\n",
      "[epoch 3], [iter 800 / 1125], [train loss 146814.92188]\n",
      "[epoch 3], [iter 820 / 1125], [train loss 146833.43750]\n",
      "[epoch 3], [iter 840 / 1125], [train loss 146737.48438]\n",
      "[epoch 3], [iter 860 / 1125], [train loss 146613.71875]\n",
      "[epoch 3], [iter 880 / 1125], [train loss 146456.10938]\n",
      "[epoch 3], [iter 900 / 1125], [train loss 146394.98438]\n",
      "[epoch 3], [iter 920 / 1125], [train loss 146327.23438]\n",
      "[epoch 3], [iter 940 / 1125], [train loss 146336.87500]\n",
      "[epoch 3], [iter 960 / 1125], [train loss 146219.03125]\n",
      "[epoch 3], [iter 980 / 1125], [train loss 146081.25000]\n",
      "[epoch 3], [iter 1000 / 1125], [train loss 145831.23438]\n",
      "[epoch 3], [iter 1020 / 1125], [train loss 145682.18750]\n",
      "[epoch 3], [iter 1040 / 1125], [train loss 145621.29688]\n",
      "[epoch 3], [iter 1060 / 1125], [train loss 145463.81250]\n",
      "[epoch 3], [iter 1080 / 1125], [train loss 145333.35938]\n",
      "[epoch 3], [iter 1100 / 1125], [train loss 145367.37500]\n",
      "[epoch 3], [iter 1120 / 1125], [train loss 145246.90625]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 3], [val loss 813161.12500], [acc 0.31141], [acc_cls 0.08590], [mean_iu 0.03920], [fwavacc 0.11602]\n",
      "best record: [val loss 813161.12500], [acc 0.31141], [acc_cls 0.08590], [mean_iu 0.03920], [fwavacc 0.11602], [epoch 3]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 4], [iter 20 / 1125], [train loss 137184.42188]\n",
      "[epoch 4], [iter 40 / 1125], [train loss 138180.35938]\n",
      "[epoch 4], [iter 60 / 1125], [train loss 137738.48438]\n",
      "[epoch 4], [iter 80 / 1125], [train loss 137490.46875]\n",
      "[epoch 4], [iter 100 / 1125], [train loss 138634.95312]\n",
      "[epoch 4], [iter 120 / 1125], [train loss 138393.45312]\n",
      "[epoch 4], [iter 140 / 1125], [train loss 138798.98438]\n",
      "[epoch 4], [iter 160 / 1125], [train loss 138857.45312]\n",
      "[epoch 4], [iter 180 / 1125], [train loss 139058.84375]\n",
      "[epoch 4], [iter 200 / 1125], [train loss 139041.70312]\n",
      "[epoch 4], [iter 220 / 1125], [train loss 138946.43750]\n",
      "[epoch 4], [iter 240 / 1125], [train loss 139005.28125]\n",
      "[epoch 4], [iter 260 / 1125], [train loss 139588.70312]\n",
      "[epoch 4], [iter 280 / 1125], [train loss 139431.98438]\n",
      "[epoch 4], [iter 300 / 1125], [train loss 139050.14062]\n",
      "[epoch 4], [iter 320 / 1125], [train loss 139431.57812]\n",
      "[epoch 4], [iter 340 / 1125], [train loss 139312.89062]\n",
      "[epoch 4], [iter 360 / 1125], [train loss 139363.67188]\n",
      "[epoch 4], [iter 380 / 1125], [train loss 139399.57812]\n",
      "[epoch 4], [iter 400 / 1125], [train loss 139674.17188]\n",
      "[epoch 4], [iter 420 / 1125], [train loss 139613.35938]\n",
      "[epoch 4], [iter 440 / 1125], [train loss 139364.89062]\n",
      "[epoch 4], [iter 460 / 1125], [train loss 139227.45312]\n",
      "[epoch 4], [iter 480 / 1125], [train loss 139150.79688]\n",
      "[epoch 4], [iter 500 / 1125], [train loss 139319.40625]\n",
      "[epoch 4], [iter 520 / 1125], [train loss 139399.45312]\n",
      "[epoch 4], [iter 540 / 1125], [train loss 139460.51562]\n",
      "[epoch 4], [iter 560 / 1125], [train loss 139209.76562]\n",
      "[epoch 4], [iter 580 / 1125], [train loss 139009.54688]\n",
      "[epoch 4], [iter 600 / 1125], [train loss 138871.89062]\n",
      "[epoch 4], [iter 620 / 1125], [train loss 138829.96875]\n",
      "[epoch 4], [iter 640 / 1125], [train loss 138834.56250]\n",
      "[epoch 4], [iter 660 / 1125], [train loss 138766.01562]\n",
      "[epoch 4], [iter 680 / 1125], [train loss 138741.42188]\n",
      "[epoch 4], [iter 700 / 1125], [train loss 138600.70312]\n",
      "[epoch 4], [iter 720 / 1125], [train loss 138473.00000]\n",
      "[epoch 4], [iter 740 / 1125], [train loss 138370.68750]\n",
      "[epoch 4], [iter 760 / 1125], [train loss 138322.07812]\n",
      "[epoch 4], [iter 780 / 1125], [train loss 138319.31250]\n",
      "[epoch 4], [iter 800 / 1125], [train loss 138258.48438]\n",
      "[epoch 4], [iter 820 / 1125], [train loss 138082.50000]\n",
      "[epoch 4], [iter 840 / 1125], [train loss 138208.21875]\n",
      "[epoch 4], [iter 860 / 1125], [train loss 138194.84375]\n",
      "[epoch 4], [iter 880 / 1125], [train loss 138095.82812]\n",
      "[epoch 4], [iter 900 / 1125], [train loss 137928.59375]\n",
      "[epoch 4], [iter 920 / 1125], [train loss 137786.18750]\n",
      "[epoch 4], [iter 940 / 1125], [train loss 137893.93750]\n",
      "[epoch 4], [iter 960 / 1125], [train loss 137882.84375]\n",
      "[epoch 4], [iter 980 / 1125], [train loss 137851.53125]\n",
      "[epoch 4], [iter 1000 / 1125], [train loss 137879.57812]\n",
      "[epoch 4], [iter 1020 / 1125], [train loss 137823.75000]\n",
      "[epoch 4], [iter 1040 / 1125], [train loss 137844.87500]\n",
      "[epoch 4], [iter 1060 / 1125], [train loss 137800.37500]\n",
      "[epoch 4], [iter 1080 / 1125], [train loss 137654.76562]\n",
      "[epoch 4], [iter 1100 / 1125], [train loss 137597.50000]\n",
      "[epoch 4], [iter 1120 / 1125], [train loss 137630.67188]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 4], [val loss 859558.75000], [acc 0.31513], [acc_cls 0.09493], [mean_iu 0.04394], [fwavacc 0.11856]\n",
      "best record: [val loss 859558.75000], [acc 0.31513], [acc_cls 0.09493], [mean_iu 0.04394], [fwavacc 0.11856], [epoch 4]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 5], [iter 20 / 1125], [train loss 132766.67188]\n",
      "[epoch 5], [iter 40 / 1125], [train loss 131909.70312]\n",
      "[epoch 5], [iter 60 / 1125], [train loss 132651.79688]\n",
      "[epoch 5], [iter 80 / 1125], [train loss 133588.01562]\n",
      "[epoch 5], [iter 100 / 1125], [train loss 134187.85938]\n",
      "[epoch 5], [iter 120 / 1125], [train loss 134098.76562]\n",
      "[epoch 5], [iter 140 / 1125], [train loss 134271.26562]\n",
      "[epoch 5], [iter 160 / 1125], [train loss 134485.56250]\n",
      "[epoch 5], [iter 180 / 1125], [train loss 134524.29688]\n",
      "[epoch 5], [iter 200 / 1125], [train loss 134338.73438]\n",
      "[epoch 5], [iter 220 / 1125], [train loss 134347.90625]\n",
      "[epoch 5], [iter 240 / 1125], [train loss 134037.62500]\n",
      "[epoch 5], [iter 260 / 1125], [train loss 134126.51562]\n",
      "[epoch 5], [iter 280 / 1125], [train loss 134043.21875]\n",
      "[epoch 5], [iter 300 / 1125], [train loss 134088.23438]\n",
      "[epoch 5], [iter 320 / 1125], [train loss 134200.50000]\n",
      "[epoch 5], [iter 340 / 1125], [train loss 134158.79688]\n",
      "[epoch 5], [iter 360 / 1125], [train loss 134173.68750]\n",
      "[epoch 5], [iter 380 / 1125], [train loss 134404.28125]\n",
      "[epoch 5], [iter 400 / 1125], [train loss 134549.15625]\n",
      "[epoch 5], [iter 420 / 1125], [train loss 134442.07812]\n",
      "[epoch 5], [iter 440 / 1125], [train loss 134158.73438]\n",
      "[epoch 5], [iter 460 / 1125], [train loss 134075.60938]\n",
      "[epoch 5], [iter 480 / 1125], [train loss 134215.79688]\n",
      "[epoch 5], [iter 500 / 1125], [train loss 134091.12500]\n",
      "[epoch 5], [iter 520 / 1125], [train loss 134058.70312]\n",
      "[epoch 5], [iter 540 / 1125], [train loss 134082.82812]\n",
      "[epoch 5], [iter 560 / 1125], [train loss 133991.92188]\n",
      "[epoch 5], [iter 580 / 1125], [train loss 133863.60938]\n",
      "[epoch 5], [iter 600 / 1125], [train loss 133912.43750]\n",
      "[epoch 5], [iter 620 / 1125], [train loss 133850.84375]\n",
      "[epoch 5], [iter 640 / 1125], [train loss 133784.29688]\n",
      "[epoch 5], [iter 660 / 1125], [train loss 133746.68750]\n",
      "[epoch 5], [iter 680 / 1125], [train loss 133755.81250]\n",
      "[epoch 5], [iter 700 / 1125], [train loss 133683.81250]\n",
      "[epoch 5], [iter 720 / 1125], [train loss 133576.31250]\n",
      "[epoch 5], [iter 740 / 1125], [train loss 133543.96875]\n",
      "[epoch 5], [iter 760 / 1125], [train loss 133470.03125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5], [iter 780 / 1125], [train loss 133409.31250]\n",
      "[epoch 5], [iter 800 / 1125], [train loss 133366.78125]\n",
      "[epoch 5], [iter 820 / 1125], [train loss 133267.93750]\n",
      "[epoch 5], [iter 840 / 1125], [train loss 133206.78125]\n",
      "[epoch 5], [iter 860 / 1125], [train loss 133284.84375]\n",
      "[epoch 5], [iter 880 / 1125], [train loss 133189.62500]\n",
      "[epoch 5], [iter 900 / 1125], [train loss 133110.79688]\n",
      "[epoch 5], [iter 920 / 1125], [train loss 133100.90625]\n",
      "[epoch 5], [iter 940 / 1125], [train loss 133124.64062]\n",
      "[epoch 5], [iter 960 / 1125], [train loss 133154.17188]\n",
      "[epoch 5], [iter 980 / 1125], [train loss 133108.35938]\n",
      "[epoch 5], [iter 1000 / 1125], [train loss 133019.92188]\n",
      "[epoch 5], [iter 1020 / 1125], [train loss 132932.90625]\n",
      "[epoch 5], [iter 1040 / 1125], [train loss 132874.42188]\n",
      "[epoch 5], [iter 1060 / 1125], [train loss 132875.71875]\n",
      "[epoch 5], [iter 1080 / 1125], [train loss 132825.59375]\n",
      "[epoch 5], [iter 1100 / 1125], [train loss 132723.89062]\n",
      "[epoch 5], [iter 1120 / 1125], [train loss 132663.70312]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 5], [val loss 896450.06250], [acc 0.31840], [acc_cls 0.10289], [mean_iu 0.04660], [fwavacc 0.12211]\n",
      "best record: [val loss 896450.06250], [acc 0.31840], [acc_cls 0.10289], [mean_iu 0.04660], [fwavacc 0.12211], [epoch 5]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 6], [iter 20 / 1125], [train loss 126404.20312]\n",
      "[epoch 6], [iter 40 / 1125], [train loss 129992.31250]\n",
      "[epoch 6], [iter 60 / 1125], [train loss 129956.39062]\n",
      "[epoch 6], [iter 80 / 1125], [train loss 129605.53906]\n",
      "[epoch 6], [iter 100 / 1125], [train loss 130138.83594]\n",
      "[epoch 6], [iter 120 / 1125], [train loss 131080.40625]\n",
      "[epoch 6], [iter 140 / 1125], [train loss 131359.23438]\n",
      "[epoch 6], [iter 160 / 1125], [train loss 130978.02344]\n",
      "[epoch 6], [iter 180 / 1125], [train loss 130821.49219]\n",
      "[epoch 6], [iter 200 / 1125], [train loss 130789.14062]\n",
      "[epoch 6], [iter 220 / 1125], [train loss 130516.42188]\n",
      "[epoch 6], [iter 240 / 1125], [train loss 130433.65625]\n",
      "[epoch 6], [iter 260 / 1125], [train loss 130482.00000]\n",
      "[epoch 6], [iter 280 / 1125], [train loss 130598.65625]\n",
      "[epoch 6], [iter 300 / 1125], [train loss 130480.40625]\n",
      "[epoch 6], [iter 320 / 1125], [train loss 130232.33594]\n",
      "[epoch 6], [iter 340 / 1125], [train loss 130235.94531]\n",
      "[epoch 6], [iter 360 / 1125], [train loss 130098.11719]\n",
      "[epoch 6], [iter 380 / 1125], [train loss 130080.97656]\n",
      "[epoch 6], [iter 400 / 1125], [train loss 130116.62500]\n",
      "[epoch 6], [iter 420 / 1125], [train loss 130080.14844]\n",
      "[epoch 6], [iter 440 / 1125], [train loss 130014.30469]\n",
      "[epoch 6], [iter 460 / 1125], [train loss 129955.18750]\n",
      "[epoch 6], [iter 480 / 1125], [train loss 129991.54688]\n",
      "[epoch 6], [iter 500 / 1125], [train loss 129930.39844]\n",
      "[epoch 6], [iter 520 / 1125], [train loss 129963.00000]\n",
      "[epoch 6], [iter 540 / 1125], [train loss 129960.02344]\n",
      "[epoch 6], [iter 560 / 1125], [train loss 129981.35938]\n",
      "[epoch 6], [iter 580 / 1125], [train loss 129923.36719]\n",
      "[epoch 6], [iter 600 / 1125], [train loss 129808.40625]\n",
      "[epoch 6], [iter 620 / 1125], [train loss 129833.54688]\n",
      "[epoch 6], [iter 640 / 1125], [train loss 129853.96094]\n",
      "[epoch 6], [iter 660 / 1125], [train loss 129816.88281]\n",
      "[epoch 6], [iter 680 / 1125], [train loss 129813.03906]\n",
      "[epoch 6], [iter 700 / 1125], [train loss 129809.66406]\n",
      "[epoch 6], [iter 720 / 1125], [train loss 129822.64844]\n",
      "[epoch 6], [iter 740 / 1125], [train loss 129788.28125]\n",
      "[epoch 6], [iter 760 / 1125], [train loss 129813.50000]\n",
      "[epoch 6], [iter 780 / 1125], [train loss 129743.48438]\n",
      "[epoch 6], [iter 800 / 1125], [train loss 129687.30469]\n",
      "[epoch 6], [iter 820 / 1125], [train loss 129590.18750]\n",
      "[epoch 6], [iter 840 / 1125], [train loss 129496.63281]\n",
      "[epoch 6], [iter 860 / 1125], [train loss 129482.47656]\n",
      "[epoch 6], [iter 880 / 1125], [train loss 129349.75000]\n",
      "[epoch 6], [iter 900 / 1125], [train loss 129383.42188]\n",
      "[epoch 6], [iter 920 / 1125], [train loss 129426.00781]\n",
      "[epoch 6], [iter 940 / 1125], [train loss 129412.15625]\n",
      "[epoch 6], [iter 960 / 1125], [train loss 129418.43750]\n",
      "[epoch 6], [iter 980 / 1125], [train loss 129386.29688]\n",
      "[epoch 6], [iter 1000 / 1125], [train loss 129337.63281]\n",
      "[epoch 6], [iter 1020 / 1125], [train loss 129272.42188]\n",
      "[epoch 6], [iter 1040 / 1125], [train loss 129289.36719]\n",
      "[epoch 6], [iter 1060 / 1125], [train loss 129315.78906]\n",
      "[epoch 6], [iter 1080 / 1125], [train loss 129252.96094]\n",
      "[epoch 6], [iter 1100 / 1125], [train loss 129215.64062]\n",
      "[epoch 6], [iter 1120 / 1125], [train loss 129179.51562]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 6], [val loss 915445.93750], [acc 0.32208], [acc_cls 0.10583], [mean_iu 0.04875], [fwavacc 0.12295]\n",
      "best record: [val loss 915445.93750], [acc 0.32208], [acc_cls 0.10583], [mean_iu 0.04875], [fwavacc 0.12295], [epoch 6]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 7], [iter 20 / 1125], [train loss 127537.89062]\n",
      "[epoch 7], [iter 40 / 1125], [train loss 129322.25000]\n",
      "[epoch 7], [iter 60 / 1125], [train loss 128122.85938]\n",
      "[epoch 7], [iter 80 / 1125], [train loss 128231.27344]\n",
      "[epoch 7], [iter 100 / 1125], [train loss 128347.58594]\n",
      "[epoch 7], [iter 120 / 1125], [train loss 128061.19531]\n",
      "[epoch 7], [iter 140 / 1125], [train loss 127817.34375]\n",
      "[epoch 7], [iter 160 / 1125], [train loss 127275.39062]\n",
      "[epoch 7], [iter 180 / 1125], [train loss 127190.17969]\n",
      "[epoch 7], [iter 200 / 1125], [train loss 126765.21875]\n",
      "[epoch 7], [iter 220 / 1125], [train loss 126914.12500]\n",
      "[epoch 7], [iter 240 / 1125], [train loss 126914.73438]\n",
      "[epoch 7], [iter 260 / 1125], [train loss 126802.41406]\n",
      "[epoch 7], [iter 280 / 1125], [train loss 126853.58594]\n",
      "[epoch 7], [iter 300 / 1125], [train loss 126615.63281]\n",
      "[epoch 7], [iter 320 / 1125], [train loss 126791.96094]\n",
      "[epoch 7], [iter 340 / 1125], [train loss 126770.11719]\n",
      "[epoch 7], [iter 360 / 1125], [train loss 126708.64844]\n",
      "[epoch 7], [iter 380 / 1125], [train loss 126833.49219]\n",
      "[epoch 7], [iter 400 / 1125], [train loss 126916.42969]\n",
      "[epoch 7], [iter 420 / 1125], [train loss 126640.10156]\n",
      "[epoch 7], [iter 440 / 1125], [train loss 126565.96875]\n",
      "[epoch 7], [iter 460 / 1125], [train loss 126463.69531]\n",
      "[epoch 7], [iter 480 / 1125], [train loss 126362.86719]\n",
      "[epoch 7], [iter 500 / 1125], [train loss 126260.41406]\n",
      "[epoch 7], [iter 520 / 1125], [train loss 126340.92969]\n",
      "[epoch 7], [iter 540 / 1125], [train loss 126417.82031]\n",
      "[epoch 7], [iter 560 / 1125], [train loss 126571.29688]\n",
      "[epoch 7], [iter 580 / 1125], [train loss 126444.56250]\n",
      "[epoch 7], [iter 600 / 1125], [train loss 126554.46875]\n",
      "[epoch 7], [iter 620 / 1125], [train loss 126447.01562]\n",
      "[epoch 7], [iter 640 / 1125], [train loss 126447.37500]\n",
      "[epoch 7], [iter 660 / 1125], [train loss 126559.19531]\n",
      "[epoch 7], [iter 680 / 1125], [train loss 126628.50000]\n",
      "[epoch 7], [iter 700 / 1125], [train loss 126507.72656]\n",
      "[epoch 7], [iter 720 / 1125], [train loss 126416.21094]\n",
      "[epoch 7], [iter 740 / 1125], [train loss 126436.16406]\n",
      "[epoch 7], [iter 760 / 1125], [train loss 126488.49219]\n",
      "[epoch 7], [iter 780 / 1125], [train loss 126385.66406]\n",
      "[epoch 7], [iter 800 / 1125], [train loss 126392.71875]\n",
      "[epoch 7], [iter 820 / 1125], [train loss 126301.00781]\n",
      "[epoch 7], [iter 840 / 1125], [train loss 126409.32031]\n",
      "[epoch 7], [iter 860 / 1125], [train loss 126480.70312]\n",
      "[epoch 7], [iter 880 / 1125], [train loss 126540.18750]\n",
      "[epoch 7], [iter 900 / 1125], [train loss 126596.27344]\n",
      "[epoch 7], [iter 920 / 1125], [train loss 126649.00000]\n",
      "[epoch 7], [iter 940 / 1125], [train loss 126660.03906]\n",
      "[epoch 7], [iter 960 / 1125], [train loss 126650.24219]\n",
      "[epoch 7], [iter 980 / 1125], [train loss 126594.51562]\n",
      "[epoch 7], [iter 1000 / 1125], [train loss 126446.09375]\n",
      "[epoch 7], [iter 1020 / 1125], [train loss 126478.85938]\n",
      "[epoch 7], [iter 1040 / 1125], [train loss 126429.80469]\n",
      "[epoch 7], [iter 1060 / 1125], [train loss 126469.85938]\n",
      "[epoch 7], [iter 1080 / 1125], [train loss 126454.54688]\n",
      "[epoch 7], [iter 1100 / 1125], [train loss 126396.04688]\n",
      "[epoch 7], [iter 1120 / 1125], [train loss 126357.29688]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 7], [val loss 932473.50000], [acc 0.32464], [acc_cls 0.11395], [mean_iu 0.05313], [fwavacc 0.12642]\n",
      "best record: [val loss 932473.50000], [acc 0.32464], [acc_cls 0.11395], [mean_iu 0.05313], [fwavacc 0.12642], [epoch 7]\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8], [iter 20 / 1125], [train loss 125842.87500]\n",
      "[epoch 8], [iter 40 / 1125], [train loss 128921.00000]\n",
      "[epoch 8], [iter 60 / 1125], [train loss 127608.75000]\n",
      "[epoch 8], [iter 80 / 1125], [train loss 126899.71094]\n",
      "[epoch 8], [iter 100 / 1125], [train loss 125939.97656]\n",
      "[epoch 8], [iter 120 / 1125], [train loss 125136.46875]\n",
      "[epoch 8], [iter 140 / 1125], [train loss 125443.21875]\n",
      "[epoch 8], [iter 160 / 1125], [train loss 125340.31250]\n",
      "[epoch 8], [iter 180 / 1125], [train loss 125598.93750]\n",
      "[epoch 8], [iter 200 / 1125], [train loss 125512.89844]\n",
      "[epoch 8], [iter 220 / 1125], [train loss 125728.06250]\n",
      "[epoch 8], [iter 240 / 1125], [train loss 125463.76562]\n",
      "[epoch 8], [iter 260 / 1125], [train loss 125106.89062]\n",
      "[epoch 8], [iter 280 / 1125], [train loss 124982.92969]\n",
      "[epoch 8], [iter 300 / 1125], [train loss 124960.21875]\n",
      "[epoch 8], [iter 320 / 1125], [train loss 124734.89844]\n",
      "[epoch 8], [iter 340 / 1125], [train loss 124770.96875]\n",
      "[epoch 8], [iter 360 / 1125], [train loss 124804.09375]\n",
      "[epoch 8], [iter 380 / 1125], [train loss 124976.31250]\n",
      "[epoch 8], [iter 400 / 1125], [train loss 125107.19531]\n",
      "[epoch 8], [iter 420 / 1125], [train loss 125097.61719]\n",
      "[epoch 8], [iter 440 / 1125], [train loss 124996.62500]\n",
      "[epoch 8], [iter 460 / 1125], [train loss 125106.64844]\n",
      "[epoch 8], [iter 480 / 1125], [train loss 124898.23438]\n",
      "[epoch 8], [iter 500 / 1125], [train loss 124844.57812]\n",
      "[epoch 8], [iter 520 / 1125], [train loss 124816.07812]\n",
      "[epoch 8], [iter 540 / 1125], [train loss 124868.66406]\n",
      "[epoch 8], [iter 560 / 1125], [train loss 124750.01562]\n",
      "[epoch 8], [iter 580 / 1125], [train loss 124714.70312]\n",
      "[epoch 8], [iter 600 / 1125], [train loss 124665.53906]\n",
      "[epoch 8], [iter 620 / 1125], [train loss 124581.56250]\n",
      "[epoch 8], [iter 640 / 1125], [train loss 124529.45312]\n",
      "[epoch 8], [iter 660 / 1125], [train loss 124614.94531]\n",
      "[epoch 8], [iter 680 / 1125], [train loss 124629.21094]\n",
      "[epoch 8], [iter 700 / 1125], [train loss 124733.83594]\n",
      "[epoch 8], [iter 720 / 1125], [train loss 124732.67188]\n",
      "[epoch 8], [iter 740 / 1125], [train loss 124751.79688]\n",
      "[epoch 8], [iter 760 / 1125], [train loss 124755.53125]\n",
      "[epoch 8], [iter 780 / 1125], [train loss 124677.40625]\n",
      "[epoch 8], [iter 800 / 1125], [train loss 124531.42969]\n",
      "[epoch 8], [iter 820 / 1125], [train loss 124355.79688]\n",
      "[epoch 8], [iter 840 / 1125], [train loss 124385.28125]\n",
      "[epoch 8], [iter 860 / 1125], [train loss 124489.86719]\n",
      "[epoch 8], [iter 880 / 1125], [train loss 124420.50781]\n",
      "[epoch 8], [iter 900 / 1125], [train loss 124418.25000]\n",
      "[epoch 8], [iter 920 / 1125], [train loss 124381.39062]\n",
      "[epoch 8], [iter 940 / 1125], [train loss 124384.07812]\n",
      "[epoch 8], [iter 960 / 1125], [train loss 124344.85938]\n",
      "[epoch 8], [iter 980 / 1125], [train loss 124271.33594]\n",
      "[epoch 8], [iter 1000 / 1125], [train loss 124219.13281]\n",
      "[epoch 8], [iter 1020 / 1125], [train loss 124176.26562]\n",
      "[epoch 8], [iter 1040 / 1125], [train loss 124166.11719]\n",
      "[epoch 8], [iter 1060 / 1125], [train loss 124182.87500]\n",
      "[epoch 8], [iter 1080 / 1125], [train loss 124171.03906]\n",
      "[epoch 8], [iter 1100 / 1125], [train loss 124218.75000]\n",
      "[epoch 8], [iter 1120 / 1125], [train loss 124186.71875]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "[epoch 8], [val loss 928328.75000], [acc 0.32632], [acc_cls 0.12032], [mean_iu 0.05685], [fwavacc 0.12703]\n",
      "best record: [val loss 928328.75000], [acc 0.32632], [acc_cls 0.12032], [mean_iu 0.05685], [fwavacc 0.12703], [epoch 8]\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun  8 14:07:47 UTC 2020\r\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 hour 52 min'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"1 hour 52 min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
